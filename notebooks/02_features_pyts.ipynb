{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe4d9c7",
   "metadata": {},
   "source": [
    "# Feature Engineering con PyTS (HAR)\n",
    "\n",
    "En este notebook se construirá conjuntos de *features* basados en transformaciones de series temporales usando **PyTS** sobre el dataset HAR (ventanas de 2.56 s, 128 pasos, 9 canales).  \n",
    "\n",
    "**Salidas:**  \n",
    "- **Resumen de Características** (`../reports/tables/pyts_feature_summary.csv`): Un archivo de metadatos que documenta la configuración y dimensiones de cada conjunto de características generado, asegurando la trazabilidad. \n",
    "- **Set de Features PAA** (`../artifacts/pyts_features_PAA.npz`): Un archivo comprimido con características basadas en Piecewise Aggregate Approximation, que capturan la forma global de las series de tiempo.\n",
    "\n",
    "- **Set de Features BoP** (`../artifacts/pyts_features_BOP.npz`): Un archivo con características simbólicas basadas en Bag-of-Patterns, diseñadas para modelar la distribución de patrones locales y repetitivos.\n",
    "\n",
    "- **Set de Features de Imagen** (`../artifacts/pyts_features_GAF_pooled.npz`): Un archivo opcional con características extraídas de la representación de las series como imágenes (Gramian Angular Fields), capturando su textura y dinámica 2D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4383251f",
   "metadata": {},
   "source": [
    "## 1. Carga y Normalización de Datos**\n",
    "\n",
    "En este primer paso, cargamos las series de tiempo del archivo `har_processed.npz`, obteniendo `X_train` con dimensiones de muestras, pasos de tiempo y canales, junto con las etiquetas `y_train`. Posteriormente, aplicamos **normalización Z-score** de forma independiente para cada uno de los 9 canales.\n",
    "\n",
    "Este preprocesamiento es fundamental por dos razones: primero, garantiza que las señales de todos los sensores (acelerómetros y giroscopios) se encuentren en una escala común con media 0 y desviación estándar 1, evitando que los canales con magnitudes mayores dominen artificialmente el análisis. Segundo, muchas técnicas de análisis de series de tiempo, incluyendo PAA y SAX que se utilizarán posteriormente, son sensibles a la escala de los datos, por lo que la normalización asegura su funcionamiento estable y efectivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930e255",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1. Carga de datos desde el caché\n",
    "# ===============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo procesado\n",
    "har_processed_path = \"../data/har_processed.npz\"\n",
    "\n",
    "# Cargar\n",
    "data = np.load(har_processed_path, allow_pickle=True)\n",
    "X_train = data[\"X_train\"]       # (n, 128, 9)\n",
    "y_train = data[\"y_train\"]       # (n,)\n",
    "channel_names = data[\"channel_names\"]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"Canales:\", channel_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb346e9",
   "metadata": {},
   "source": [
    "## 2. Diseño de Estrategias de Características con `pyts`**\n",
    "\n",
    "Para representar las series de tiempo, se diseñaron tres estrategias complementarias que capturan diferentes aspectos de las señales de movimiento:\n",
    "\n",
    "**Estrategia 1: Resumen Global con PAA (Piecewise Aggregate Approximation)**\n",
    "\n",
    "PAA divide la secuencia de 128 puntos en segmentos más pequeños y calcula el promedio de cada uno. Esto captura la forma general de la señal: actividades dinámicas como caminar muestran patrones ondulatorios, mientras que actividades estáticas como sentarse son casi planas. Se genera un vector concatenado de características para los 9 canales.\n",
    "\n",
    "**Estrategia 2: Patrones Locales con Bag-of-Patterns (BoP)**\n",
    "\n",
    "BoP discretiza la señal en símbolos mediante SAX y cuenta la frecuencia de patrones recurrentes. Esto permite distinguir micro-patrones entre actividades similares: aunque caminar y subir escaleras son periódicas, la forma exacta de cada paso difiere. Se genera un histograma de frecuencias por canal que se concatena.\n",
    "\n",
    "**Estrategia 3: Dinámica Visual con Imágenes (GAF o RP)**\n",
    "\n",
    "Esta técnica convierte las series temporales en imágenes bidimensionales que revelan patrones de autocorrelación y dinámica no lineal. Se aplica solo a los canales más informativos (acelerómetros del cuerpo) y se resume mediante pooling para obtener vectores compactos que capturan la textura temporal de la señal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9f041",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f41cde54",
   "metadata": {},
   "source": [
    "## 3. Hiperparámetros y justificación\n",
    "\n",
    "**PAA (F1):**  \n",
    "- `n_segments = 32` (o 16 / 64 como sensibilidad)  \n",
    "  - 128 → 32 resume 4 muestras por segmento: equilibrio entre **detalle** y **ruido**.  \n",
    "  - Mantiene vector por canal manejable (32) → total 9×32 = 288 *features*.\n",
    "\n",
    "**Bag-of-Patterns (F2):**  \n",
    "- `window_size = 16` (segmentos locales suficientemente cortos para captar un “medio paso”).  \n",
    "- `word_size = 8` (resumen PAA interno por ventana para robustez).  \n",
    "- `n_bins = 6` (cuantización SAX suficiente sin sobrediscretizar).  \n",
    "- `norm=True` (usar z-normalización previa).  \n",
    "  - Estos valores son comunes en literatura SAX y funcionan bien con ventanas de 128 pasos.\n",
    "\n",
    "**Imágenes (F3, opcional):**  \n",
    "- GAF o RP con `image_size = 64` → *pooling* a `8×8` (o medias por bloques 8×8).  \n",
    "- **Canales:** iniciar con `body_acc_{x,y,z}` (3) para evitar explosión dimensional.  \n",
    "  - 3×(8×8)=192 *features* si se aplana, o agregar promedios por filas/columnas para vectores más pequeños.\n",
    "\n",
    "> **Criterio pedagógico:** parámetros buscan **estabilidad**, **baja dimensionalidad** y **interpretabilidad**, evitando *overfitting* y costos excesivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ce314",
   "metadata": {},
   "source": [
    "## 4. Pipeline de construcción\n",
    "\n",
    "1. **Normalizar** `X_train` por canal (z-score).  \n",
    "2. **F1-PAA:** aplicar por canal → concatenar → `X_PAA` `(n, 9*M)`.  \n",
    "3. **F2-Bag-of-Patterns:** aplicar por canal → concatenar histogramas → `X_BOP`.  \n",
    "4. **F3-Imagen (opcional):** GAF/RP en 3 canales `body_acc_*` → *pooling* 8×8 → concatenar → `X_IMG`.  \n",
    "5. **Chequear varianza** y remover columnas constantes.  \n",
    "6. **Guardar artefactos** (`.npz` + CSV de resumen con dimensiones, tiempos y parámetros)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3a338",
   "metadata": {},
   "source": [
    "## 5. Validaciones rápidas (sin entrenamiento)\n",
    "\n",
    "- **Sanity checks:** dimensiones de salida, ausencia de NaN/inf, varianza > 0.  \n",
    "- **Separabilidad preliminar:** PCA/UMAP con `X_PAA` y `X_BOP` (2D) para visualizar si hay agrupamientos por actividad.  \n",
    "- **Correlaciones:** matriz de correlación entre *features* de F1 y F2 para descartar redundancias extremas.\n",
    "\n",
    "> Nota: El modelado y las métricas formales (Accuracy, F1, Confusión) se realizarán en el notebook 03."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b1ec4",
   "metadata": {},
   "source": [
    "## 6. Exportación para el paper y trazabilidad\n",
    "\n",
    "- Guardar **resumen de *features*** (`../reports/tables/pyts_feature_summary.csv`) con:  \n",
    "  - `set_name`, `n_features`, `n_segments / window_size / word_size / n_bins`, canales usados, normalización y compute_time_sec (tiempo de cómputo en segundos que tomó generar cada conjunto de features).\n",
    "- Guardar **figuras** de:  \n",
    "  - PCA de `X_PAA` y de `X_BOP` (coloreado por actividad).  \n",
    "- Guardar artefactos:  \n",
    "  - `../artifacts/pyts_features_PAA.npz` (X_PAA, y, meta)  \n",
    "  - `../artifacts/pyts_features_BOP.npz` (X_BOP, y, meta)  \n",
    "  - *(Opcional)* `../artifacts/pyts_features_GAF_pooled.npz`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef44753",
   "metadata": {},
   "source": [
    "## 7. Limitaciones y plan para tsfresh\n",
    "\n",
    "- **PyTS** resume forma global (PAA) y patrones locales discretizados (BoP), pero no agota todos los estadísticos temporales.  \n",
    "- **tsfresh** complementará con **features estadísticas masivas** (autocorrelación, entropías, percentiles, coeficientes de Fourier), seguidas de **selección de *features***.  \n",
    "- En el notebook 03 (modelado), compararemos desempeño usando:  \n",
    "  - Solo PyTS (F1/F2)  \n",
    "  - Solo tsfresh  \n",
    "  - **Combinación PyTS + tsfresh** (si la dimensionalidad y el *overfitting* lo permiten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e719476",
   "metadata": {},
   "source": [
    "## 8. Conclusiones (PyTS)\n",
    "\n",
    "- Se definieron y justificaron **tres familias** de *features* en PyTS: **PAA (compacto)**, **BoP (motivos locales)** y **GAF/RP (opcional, firma visual)**.  \n",
    "- Los parámetros propuestos priorizan **robustez, baja dimensionalidad e interpretabilidad**.  \n",
    "- Dejaremos listas las matrices de *features* y el resumen para integrarlas en el **notebook de modelado** y en el **paper** (sección Metodología/Experimentación).\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
